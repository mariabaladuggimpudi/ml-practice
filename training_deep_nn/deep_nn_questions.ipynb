{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b734bed1",
   "metadata": {},
   "source": [
    "Exercise: Build a DNN with 20 hidden layers of 100 neurons each (that's too many, but it's the point of this exercise). Use He initialization and the ELU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0abcca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5984ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 activation=\"elu\",\n",
    "                                 kernel_initializer=\"he_normal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5554e188",
   "metadata": {},
   "source": [
    "Exercise: Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with keras.datasets.cifar10.load_data(). The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you'll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model's architecture or hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7b86271",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0add5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f87b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6328ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d10f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2297267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 show tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "535219dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4266c3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kill: 6372: No such process\n"
     ]
    }
   ],
   "source": [
    "!kill 6372"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1a32710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-71529476dd23a592\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-71529476dd23a592\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=c:\\\\users\\\\ma6114132\\\\PycharmProjects\\\\ml_practice\\\\training_deep_nn\\\\my_cifar10_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "389b0158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1407/1407 [==============================] - 12s 6ms/step - loss: 3.6437 - accuracy: 0.1721 - val_loss: 2.0976 - val_accuracy: 0.2402\n",
      "Epoch 2/20\n",
      "  19/1407 [..............................] - ETA: 8s - loss: 2.1282 - accuracy: 0.2188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ma6114132\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 9s 6ms/step - loss: 2.0211 - accuracy: 0.2607 - val_loss: 1.9620 - val_accuracy: 0.2758\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9123 - accuracy: 0.3005 - val_loss: 1.8811 - val_accuracy: 0.2994\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.8477 - accuracy: 0.3278 - val_loss: 1.8770 - val_accuracy: 0.3248\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7863 - accuracy: 0.3501 - val_loss: 1.7672 - val_accuracy: 0.3536\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.7383 - accuracy: 0.3699 - val_loss: 1.7321 - val_accuracy: 0.3602\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6912 - accuracy: 0.3832 - val_loss: 1.7107 - val_accuracy: 0.3786\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6547 - accuracy: 0.4043 - val_loss: 1.6362 - val_accuracy: 0.4020\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6226 - accuracy: 0.4134 - val_loss: 1.6374 - val_accuracy: 0.4116\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5992 - accuracy: 0.4271 - val_loss: 1.6560 - val_accuracy: 0.3938\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5740 - accuracy: 0.4336 - val_loss: 1.6086 - val_accuracy: 0.4242\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5517 - accuracy: 0.4410 - val_loss: 1.6661 - val_accuracy: 0.4042\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5336 - accuracy: 0.4460 - val_loss: 1.6028 - val_accuracy: 0.4272\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5186 - accuracy: 0.4546 - val_loss: 1.6039 - val_accuracy: 0.4174\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4993 - accuracy: 0.4610 - val_loss: 1.5880 - val_accuracy: 0.4346\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4811 - accuracy: 0.4675 - val_loss: 1.5561 - val_accuracy: 0.4402\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4654 - accuracy: 0.4716 - val_loss: 1.5592 - val_accuracy: 0.4362\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4494 - accuracy: 0.4799 - val_loss: 1.5506 - val_accuracy: 0.4454\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4392 - accuracy: 0.4840 - val_loss: 1.5296 - val_accuracy: 0.4524\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4275 - accuracy: 0.4848 - val_loss: 1.5616 - val_accuracy: 0.4462\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x27271281460>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd26283",
   "metadata": {},
   "source": [
    "Exercise: Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?\n",
    "\n",
    "The code below is very similar to the code above, with a few changes:\n",
    "\n",
    "I added a BN layer after every Dense layer (before the activation function), except for the output layer. I also added a BN layer before the first hidden layer.\n",
    "I changed the learning rate to 5e-4. I experimented with 1e-5, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3 and 3e-3, and I chose the one with the best validation performance after 20 epochs.\n",
    "I renamed the run directories to run_bn_* and the model file name to my_cifar10_bn_model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35e6233d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1407/1407 [==============================] - 24s 10ms/step - loss: 1.8465 - accuracy: 0.3376 - val_loss: 1.6529 - val_accuracy: 0.4118\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.6714 - accuracy: 0.4047 - val_loss: 1.5763 - val_accuracy: 0.4436\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.6008 - accuracy: 0.4306 - val_loss: 1.5369 - val_accuracy: 0.4496\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5487 - accuracy: 0.4512 - val_loss: 1.4913 - val_accuracy: 0.4658\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5080 - accuracy: 0.4640 - val_loss: 1.4239 - val_accuracy: 0.4916\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4709 - accuracy: 0.4782 - val_loss: 1.4493 - val_accuracy: 0.4830\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4345 - accuracy: 0.4875 - val_loss: 1.4138 - val_accuracy: 0.4918\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.4095 - accuracy: 0.5001 - val_loss: 1.3894 - val_accuracy: 0.5046\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3848 - accuracy: 0.5094 - val_loss: 1.3861 - val_accuracy: 0.5046\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3615 - accuracy: 0.5172 - val_loss: 1.3671 - val_accuracy: 0.5146\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3408 - accuracy: 0.5259 - val_loss: 1.3662 - val_accuracy: 0.5174\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3198 - accuracy: 0.5334 - val_loss: 1.3773 - val_accuracy: 0.5076\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3009 - accuracy: 0.5370 - val_loss: 1.3713 - val_accuracy: 0.5132\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2809 - accuracy: 0.5463 - val_loss: 1.3586 - val_accuracy: 0.5222\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.2635 - accuracy: 0.5540 - val_loss: 1.3561 - val_accuracy: 0.5290\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2538 - accuracy: 0.5572 - val_loss: 1.3633 - val_accuracy: 0.5200\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2328 - accuracy: 0.5670 - val_loss: 1.3397 - val_accuracy: 0.5256\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2154 - accuracy: 0.5700 - val_loss: 1.3569 - val_accuracy: 0.5348\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2018 - accuracy: 0.5744 - val_loss: 1.3378 - val_accuracy: 0.5298\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1896 - accuracy: 0.5805 - val_loss: 1.3710 - val_accuracy: 0.5208\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 1.3378 - accuracy: 0.5298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3377814292907715, 0.5297999978065491]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"elu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4818b0",
   "metadata": {},
   "source": [
    "Exercise: Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd38af84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 14s 7ms/step - loss: 1.9271 - accuracy: 0.3069 - val_loss: 1.8017 - val_accuracy: 0.3742\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.7126 - accuracy: 0.3953 - val_loss: 1.6735 - val_accuracy: 0.4052\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.6181 - accuracy: 0.4308 - val_loss: 1.6342 - val_accuracy: 0.4318\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5524 - accuracy: 0.4524 - val_loss: 1.6040 - val_accuracy: 0.4534\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.4951 - accuracy: 0.4735 - val_loss: 1.5597 - val_accuracy: 0.4630\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4521 - accuracy: 0.4918 - val_loss: 1.5167 - val_accuracy: 0.4654\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4099 - accuracy: 0.5077 - val_loss: 1.5013 - val_accuracy: 0.4716\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3672 - accuracy: 0.5226 - val_loss: 1.4751 - val_accuracy: 0.4932\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3373 - accuracy: 0.5358 - val_loss: 1.4919 - val_accuracy: 0.4768\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.3078 - accuracy: 0.5460 - val_loss: 1.4983 - val_accuracy: 0.4968\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4751 - accuracy: 0.4932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4750993251800537, 0.49320000410079956]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_selu_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=10,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cec6654",
   "metadata": {},
   "source": [
    "Exercise: Try regularizing the model with alpha dropout. Then, without retraining your model, see if you can achieve better accuracy using MC Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d913782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1407/1407 [==============================] - 14s 7ms/step - loss: 1.8958 - accuracy: 0.3271 - val_loss: 1.7390 - val_accuracy: 0.3960\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6760 - accuracy: 0.4119 - val_loss: 1.6544 - val_accuracy: 0.4194\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.5826 - accuracy: 0.4460 - val_loss: 1.6480 - val_accuracy: 0.4298\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.5221 - accuracy: 0.4645 - val_loss: 1.6066 - val_accuracy: 0.4488\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.4622 - accuracy: 0.4901 - val_loss: 1.5864 - val_accuracy: 0.4686\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.4171 - accuracy: 0.5061 - val_loss: 1.5427 - val_accuracy: 0.4700\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3689 - accuracy: 0.5230 - val_loss: 1.5171 - val_accuracy: 0.4756\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3267 - accuracy: 0.5368 - val_loss: 1.4660 - val_accuracy: 0.4920\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2895 - accuracy: 0.5508 - val_loss: 1.5481 - val_accuracy: 0.4766\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2561 - accuracy: 0.5640 - val_loss: 1.5879 - val_accuracy: 0.4816\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.2254 - accuracy: 0.5742 - val_loss: 1.5524 - val_accuracy: 0.4996\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1940 - accuracy: 0.5875 - val_loss: 1.5274 - val_accuracy: 0.4934\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1632 - accuracy: 0.5983 - val_loss: 1.6175 - val_accuracy: 0.4942\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1478 - accuracy: 0.6022 - val_loss: 1.5504 - val_accuracy: 0.5056\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.1130 - accuracy: 0.6166 - val_loss: 1.6174 - val_accuracy: 0.4958\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.0867 - accuracy: 0.6254 - val_loss: 1.7165 - val_accuracy: 0.4960\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0698 - accuracy: 0.6329 - val_loss: 1.6328 - val_accuracy: 0.4946\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0514 - accuracy: 0.6379 - val_loss: 1.6884 - val_accuracy: 0.4956\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.0212 - accuracy: 0.6488 - val_loss: 1.7743 - val_accuracy: 0.4996\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0034 - accuracy: 0.6541 - val_loss: 1.6721 - val_accuracy: 0.4994\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.4660 - accuracy: 0.4920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4660210609436035, 0.492000013589859]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_alpha_dropout_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_alpha_dropout_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=20,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_alpha_dropout_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeebe45",
   "metadata": {},
   "source": [
    "Exercise: Retrain your model using 1cycle scheduling and see if it improves training speed and model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d05a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60a261aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.learning_rate, self.model.optimizer.learning_rate * self.factor)\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
    "    K.set_value(model.optimizer.learning_rate, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.learning_rate, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "835bf470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 4s 9ms/step - loss: nan - accuracy: 0.1371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9.999999747378752e-06,\n",
       " 9.615227699279785,\n",
       " 2.6770286560058594,\n",
       " 4.157665457044329)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAG1CAYAAAAFuNXgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABDRklEQVR4nO3deVxVdf7H8fdlB+FeBBVRcFdc0RQtTHPLtcxWneqn2TZaljXmTKkzLVONrTPZWC7lZM6YpqW2KWrlngu4hfsuyCoqXARBlvv7w+lOJCogcODwej4e9/HonPM9537ON5S33/M951gcDodDAAAAJuFidAEAAADliXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMhXADAABMxc3oAipbYWGhEhMT5efnJ4vFYnQ5AACgBBwOhzIzM9WgQQO5uFx9bKbGhZvExESFhoYaXQYAACiD+Ph4hYSEXLVNjQs3fn5+ki51jtVqNbgaAMCV2HPy1H3qj5Kk7X+5VZ5urgZXBCPZ7XaFhoY6f49fTY0LN79cirJarYQbAKjKPPLk4ukj6dLf2YQbSCrRlBImFAMAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFMh3AAAAFOpMuFm6tSpslgsevbZZ6/abt26derSpYu8vLzUrFkzzZw5s3IKBAAA1UKVCDfR0dGaPXu2wsPDr9ru+PHjGjJkiHr27KmdO3dq8uTJGj9+vL788stKqhQAAFR1hoeb8+fP68EHH9RHH32k2rVrX7XtzJkz1ahRI7333ntq06aNHnvsMT3yyCN65513KqlaAABQ1RkebsaNG6fbbrtNt9566zXbbt68WQMGDCiybuDAgYqJiVFeXl6x++Tm5sputxf5AAAA8zI03CxcuFDbt2/X1KlTS9Q+OTlZQUFBRdYFBQUpPz9faWlpxe4zdepU2Ww25yc0NPS66wYAAFWXYeEmPj5ezzzzjObPny8vL68S72exWIosOxyOYtf/YtKkScrIyHB+4uPjy140AACo8tyM+uLt27crNTVVXbp0ca4rKCjQ+vXrNX36dOXm5srV1bXIPvXr11dycnKRdampqXJzc1NgYGCx3+Pp6SlPT8/yPwEAAFAlGRZu+vXrp9jY2CLrHn74YbVu3VrPP//8ZcFGkiIjI/XNN98UWbdq1SpFRETI3d29QusFAADVg2Hhxs/PT+3bty+yrlatWgoMDHSunzRpkhISEjRv3jxJ0tixYzV9+nRNmDBBjz/+uDZv3qw5c+ZowYIFlV4/AAComgy/W+pqkpKSFBcX51xu2rSpli9frrVr16pTp0569dVX9f777+uee+4xsEoAAFCVGDZyU5y1a9cWWZ47d+5lbXr16qUdO3ZUTkEAAKDaqdIjNwAAAKVFuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZiaLiZMWOGwsPDZbVaZbVaFRkZqRUrVlx1n/nz56tjx47y8fFRcHCwHn74YZ05c6aSKgYAAFWdoeEmJCREb7zxhmJiYhQTE6O+fftq2LBh2rt3b7HtN27cqFGjRunRRx/V3r17tXjxYkVHR+uxxx6r5MoBAEBV5Wbklw8dOrTI8uuvv64ZM2Zoy5Ytateu3WXtt2zZoiZNmmj8+PGSpKZNm2rMmDF66623KqVeAABQ9VWZOTcFBQVauHChsrKyFBkZWWyb7t2769SpU1q+fLkcDodSUlL0xRdf6LbbbrvicXNzc2W324t8AACAeRkebmJjY+Xr6ytPT0+NHTtWS5cuVdu2bYtt2717d82fP18jRoyQh4eH6tevL39/f/3zn/+84vGnTp0qm83m/ISGhlbUqQAAgCrA8HATFhamXbt2acuWLXriiSf00EMPad++fcW23bdvn8aPH68XX3xR27dvV1RUlI4fP66xY8de8fiTJk1SRkaG8xMfH19RpwIAAKoAi8PhcBhdxK/deuutat68uWbNmnXZtpEjRyonJ0eLFy92rtu4caN69uypxMREBQcHX/P4drtdNptNGRkZslqt5Vo7AKD82HPyFP7yKknSwdcGydPN1eCKYKTS/P42fOTmtxwOh3Jzc4vdlp2dLReXoiW7uro69wMAADD0bqnJkydr8ODBCg0NVWZmphYuXKi1a9cqKipK0qVLSgkJCZo3b56kS3dXPf7445oxY4YGDhyopKQkPfvss+rWrZsaNGhg5KkAAIAqwtBwk5KSopEjRyopKUk2m03h4eGKiopS//79JUlJSUmKi4tzth89erQyMzM1ffp0Pffcc/L391ffvn315ptvGnUKAACgiqlyc24qGnNuAKB6YM4Nfq1az7kBAAC4HoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoaGmxkzZig8PFxWq1VWq1WRkZFasWLFVffJzc3VlClT1LhxY3l6eqp58+b617/+VUkVAwCAqs7NyC8PCQnRG2+8oRYtWkiSPv30Uw0bNkw7d+5Uu3btit1n+PDhSklJ0Zw5c9SiRQulpqYqPz+/MssGAABVmKHhZujQoUWWX3/9dc2YMUNbtmwpNtxERUVp3bp1OnbsmAICAiRJTZo0qYxSAQBANVFl5twUFBRo4cKFysrKUmRkZLFtvv76a0VEROitt95Sw4YN1apVK02cOFEXLly44nFzc3Nlt9uLfAAAgHkZOnIjSbGxsYqMjFROTo58fX21dOlStW3btti2x44d08aNG+Xl5aWlS5cqLS1NTz75pM6ePXvFeTdTp07VK6+8UpGnAAAAqhCLw+FwGFnAxYsXFRcXp/T0dH355Zf6+OOPtW7dumIDzoABA7RhwwYlJyfLZrNJkpYsWaJ7771XWVlZ8vb2vmyf3Nxc5ebmOpftdrtCQ0OVkZEhq9VacScGALgu9pw8hb+8SpJ08LVB8nRzNbgiGMlut8tms5Xo97fhIzceHh7OCcURERGKjo7WtGnTNGvWrMvaBgcHq2HDhs5gI0lt2rSRw+HQqVOn1LJly8v28fT0lKenZ8WdAAAAqFKqzJybXzgcjiIjLb928803KzExUefPn3euO3TokFxcXBQSElJZJQIAgCrM0HAzefJkbdiwQSdOnFBsbKymTJmitWvX6sEHH5QkTZo0SaNGjXK2f+CBBxQYGKiHH35Y+/bt0/r16/XHP/5RjzzySLGXpAAAQM1j6GWplJQUjRw5UklJSbLZbAoPD1dUVJT69+8vSUpKSlJcXJyzva+vr1avXq2nn35aERERCgwM1PDhw/Xaa68ZdQoAAKCKMXxCcWUrzYQkAIBxmFCMXyvN7+8qN+cGAADgehBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqZQp3MTHx+vUqVPO5W3btunZZ5/V7Nmzy60wAACAsihTuHnggQe0Zs0aSVJycrL69++vbdu2afLkyfrrX/9argUCAACURpnCzZ49e9StWzdJ0qJFi9S+fXv99NNP+uyzzzR37tzyrA8AAKBUyhRu8vLy5OnpKUn6/vvvdccdd0iSWrduraSkpPKrDgAAoJTKFG7atWunmTNnasOGDVq9erUGDRokSUpMTFRgYGC5FggAAFAaZQo3b775pmbNmqXevXvr/vvvV8eOHSVJX3/9tfNyFQAAgBHcyrJT7969lZaWJrvdrtq1azvX//73v5ePj0+5FQcAAFBaZRq5uXDhgnJzc53B5uTJk3rvvfd08OBB1atXr1wLBAAAKI0yhZthw4Zp3rx5kqT09HTdeOONevfdd3XnnXdqxowZ5VogAABAaZQp3OzYsUM9e/aUJH3xxRcKCgrSyZMnNW/ePL3//vvlWiAAAEBplCncZGdny8/PT5K0atUq3X333XJxcdFNN92kkydPlmuBAAAApVGmcNOiRQstW7ZM8fHxWrlypQYMGCBJSk1NldVqLdcCAQAASqNM4ebFF1/UxIkT1aRJE3Xr1k2RkZGSLo3i3HDDDSU+zowZMxQeHi6r1Sqr1arIyEitWLGiRPtu2rRJbm5u6tSpU1lOAQAAmFSZbgW/99571aNHDyUlJTmfcSNJ/fr101133VXi44SEhOiNN95QixYtJEmffvqphg0bpp07d6pdu3ZX3C8jI0OjRo1Sv379lJKSUpZTAAAAJmVxOByO6znAqVOnZLFY1LBhw3IpKCAgQG+//bYeffTRK7b53e9+p5YtW8rV1VXLli3Trl27Snx8u90um82mjIwMLqEBQBVmz8lT+MurJEkHXxskTzdXgyuCkUrz+7tMl6UKCwv117/+VTabTY0bN1ajRo3k7++vV199VYWFhWUquqCgQAsXLlRWVpbzMldxPvnkEx09elQvvfRSiY6bm5sru91e5AMAAMyrTJelpkyZojlz5uiNN97QzTffLIfDoU2bNunll19WTk6OXn/99RIfKzY2VpGRkcrJyZGvr6+WLl2qtm3bFtv28OHDeuGFF7Rhwwa5uZWs9KlTp+qVV14pcT0AAKB6K1O4+fTTT/Xxxx873wYuSR07dlTDhg315JNPlirchIWFadeuXUpPT9eXX36phx56SOvWrbss4BQUFOiBBx7QK6+8olatWpX4+JMmTdKECROcy3a7XaGhoSXeHwAAVC9lCjdnz55V69atL1vfunVrnT17tlTH8vDwcE4ojoiIUHR0tKZNm6ZZs2YVaZeZmamYmBjt3LlTTz31lKRLl8ccDofc3Ny0atUq9e3b97Lje3p6ytPTs1Q1AQCA6qtMc246duyo6dOnX7Z++vTpCg8Pv66CHA6HcnNzL1tvtVoVGxurXbt2OT9jx451jvzceOON1/W9AADAHMo0cvPWW2/ptttu0/fff6/IyEhZLBb99NNPio+P1/Lly0t8nMmTJ2vw4MEKDQ1VZmamFi5cqLVr1yoqKkrSpUtKCQkJmjdvnlxcXNS+ffsi+9erV09eXl6XrQcAADVXmUZuevXqpUOHDumuu+5Senq6zp49q7vvvlt79+7VJ598UuLjpKSkaOTIkQoLC1O/fv20detWRUVFqX///pKkpKQkxcXFlaVEAABQQ133c25+bffu3ercubMKCgrK65DljufcAED1wHNu8GsV/pwbAACAqopwAwAATIVwAwAATKVUd0vdfffdV92enp5+PbUAAABct1KFG5vNds3to0aNuq6CAAAArkepwk1pbvMGAAAwAnNuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqdTYcDN7/VFtPJxmdBkAAKCc1dhw8/4PR/TnZbFGlwEAAMpZjQ03kpSQfkGFhQ6jywAAAOWoRoebvAKH0rJyjS4DAACUI0PDzYwZMxQeHi6r1Sqr1arIyEitWLHiiu2XLFmi/v37q27dus72K1euvK4aktJzrmt/AABQtRgabkJCQvTGG28oJiZGMTEx6tu3r4YNG6a9e/cW2379+vXq37+/li9fru3bt6tPnz4aOnSodu7cWeYakjIINwAAmImbkV8+dOjQIsuvv/66ZsyYoS1btqhdu3aXtX/vvfeKLP/tb3/TV199pW+++UY33HBDmWpIyrhQpv0AAEDVZGi4+bWCggItXrxYWVlZioyMLNE+hYWFyszMVEBAwBXb5ObmKjf3f/Nq7HZ7ke3JjNwAAGAqhk8ojo2Nla+vrzw9PTV27FgtXbpUbdu2LdG+7777rrKysjR8+PArtpk6dapsNpvzExoaWmQ7l6UAADAXw8NNWFiYdu3apS1btuiJJ57QQw89pH379l1zvwULFujll1/W559/rnr16l2x3aRJk5SRkeH8xMfHF9nOZSkAAMzF8MtSHh4eatGihSQpIiJC0dHRmjZtmmbNmnXFfT7//HM9+uijWrx4sW699darHt/T01Oenp5X3M7IDQAA5mL4yM1vORyOInNkfmvBggUaPXq0PvvsM912223X/X0p9hwe5AcAgIkYOnIzefJkDR48WKGhocrMzNTChQu1du1aRUVFSbp0SSkhIUHz5s2TdCnYjBo1StOmTdNNN92k5ORkSZK3t7dsNluZavjlQX71/Lyc67YdP6uAWu5qUc+vxMeJO5Otv367V7n5hXqqTwvd2CywTPUAAIDrY+jITUpKikaOHKmwsDD169dPW7duVVRUlPr37y9JSkpKUlxcnLP9rFmzlJ+fr3Hjxik4ONj5eeaZZ8r0/XV8L12uSjj3v3k3h1Iy9bvZmzVyzrYSj+jsiDunQdPW6/v9qdpwOE0jZm/Rgm1x196xDDJz8vTVrgRlXMhzrsu4kCeHg9EnAAAkg0du5syZc9Xtc+fOLbK8du3acvtuX09XdWho1ZqDp/XljlO6oVFtSdJ3Pyep0HFpLs7O+HTN33pS7RrYNLp7E7m6WC47jsPh0N++26/siwWKaFxbjQJ8tGRngl77dp9uahaohv7e8nArnwyZV1Co0Z9Ea/vJc6rn56lB7etrf5Jd0SfOaWC7IH34YJdiawQAoCYxfEKxUfy83PX7W5przcHT+jw6Xk/0bqGG/t5auTfZ2eaPi3frWFqWluxI0Kq9yfr0kW7ycnd1bj+bdVGbj55RzMlz8nBz0QcPdlZdX0/Fnc1WzMlz6vPOWvl4uOrJ3s2VbL80cfnF29uVKezEnsrQnI3HtP3kOUlSamau5m0+6dy+cm+Knl6wQy3q+amhv5fSzl/UqXMX1LmRvwZ3CJavZ439Xw0AqGFq7G88m4+7IpsH6qZmAdpy7KxmrTuqh29uqgPJmc42x9KynP+99fhZfbjmiP7Qv5UkaVd8ukbM2qKLBYWSpAe6NVKQ9dK8nTfvDdddH2ySPSdf2RcL9M6qQ87juFgs+uuw9letLSH9gtYeTFX/NkGqXctDr3yzV//Z8r/LXO/ff4POZV3U6cxc1fH1kJuri/68bI+WxyZLSi5yrAXb4jR7/TF9NCpC20+eU1h9P7VvWLb5SQAAVAc1Ntz4e7tLkp7q01Jbjm3V0h0JsnpdWmfzdnfOaXGxSH8d1l5/XrZHM9Yd1X+2xinI6qX8gkJdLCiUm4tFDfy99WTv5s5jN6/rq21TbtXFgkIt/zlJ7/9wWM3q+mrjkTTN23xSqfZc3RcRol6t6srN9dIoTmpmjjYcSlNeQaHeWnlQZ7Mu6pWv98nTzUWZufmyWKQBbYN0T+cQDWhX/7LzqefnqTUHU2WxWBR/NltWL3c1rO2tJTsSdDj1vHq/s9bZNjzEpvu7NdLQjg0Y0QEAmI7FUcNmotrtdtlsNj02e50+evwWFRY6dMvba3Tq3AVZLJLDIb1yRzu98s1eFTqkm5oFaMHjN+mRudFac/B0kWPV9nHXD8/1VkAtjxJ99wdrjujtlQedy3X9PDUiIlRHT5/X6n0pyv/VBOZfByyrl5veHd5J/dsGlfp89yZmaPjMzcq6WKDQAG8lZ+Qor+DS99TycNWDNzXW+H4tCTkAqhx7Tp7CX14lSTr42iB5urleYw+Y2S+/vzMyMmS1Wq/atsb+RrP6XBqlcXGx6L4uofrH94fkcEgt6vnqwRsb6csdp/TzqQwNbh8si8Wid4d30r83n1RYfV/NWn9Mu+LT9dLQdiUONpI0rk8L9Q6rqy+3J+irXQk6nZmr6WuOOLd3aGiTp5uL2jWw6vnBrZ13cYUG+BSZ61Ma7RrYtGzczTp6Okv92wYpPfuiluxI0IJtcTqWlqXZ64/p35tPytfLTSG1vdW9eaCe6tNS3h78JQIAqJ5q7MjNy19E66V7IiRdmuPS480f5XBIH4+K0K1tg/TzqXT9eCBVT/ZucdkE4MLCy5+NU1p5BYVaHpukb3YnKqS2j37XLVSt6189iZYnh8OhNQdT9fLX+xR3NrvItob+3vLzcpOPh6s6hvrrkZubKjTAp9JqAwCJkRsUxchNCdi8/3fqDf299e59HXUuO0/92lx6T1V4iL/CQ/yL3dfFxXJdwUaS3F1dNKxTQw3r1PC6jlNWFotFfVsHqWfLujp5Jks5eYU6kJypd1YeVEL6/577syMuXfO3xKl7i0Dd3LyORt/cRO6uVe7B1gAAONXYcNO8nm+R5bs7hxhUibHcXV2cT2Ju39Cm/m2CtO7waVm93JRxIU+LY05p45E0rT14WmsPntaqfckaGdlE53PydTYrVyMjm8j238nZAABUBTU23PRqdeU3iddkNh933dGxgXN5WKeGij2Voa3Hz2ja94cVfeKcok+cc27/9uckPT+4tVwtFrm5WHRDo9rM1wEAGKrGhhuUXIcQmzqE2NSvTZBmrz+qI6nn5enmqoMpmTqQnKmHP4l2tq3j66nbw4Odd561a2DV0I4NyjwhGgCA0iLcoMSa1qmlqXeHO5fjz2br5a/3KjHj0tOX087n6nRmrub+dKLIflNXHNAD3Rrp4ZubKPC/7/MCAKCiEG5QZqEBPpozuqtz+WJ+oZbtStDR0+flarEor6BQ3/2cpMSMHE1fc0QLo+P1+l3t1bd1PSYlAwAqDOEG5cbDzUXDI0KLrHt+UGut3peiv68+pMOp5zXm39tl83bX5CGtNaJrI4MqBQCYGf98RoVyc3XR4A7B+ubpHnq8Z1PV9rn05OXnv4zVpCWxysrNN7pEAIDJMHKDSuHl7qopt7XVC4Pb6MM1R/Tu6kNasC1Oaw6kKqJJbbWo56vmdX3VMshXYUF+slgsRpcMAKimCDeoVK4uFj3dr6VuaFRbz3/5sxLSL+jbn5OKtLmxaYD+NChMzev6yt+n5K+3AABAItzAID1a1tHqCbdo89EzOnr6vI6kntfR01nak5ChrcfP6p4Zm2WxSL/rGqrnBoSpDndZAQBKiHADw/h4uKlfmyD1a/O/t53HncnWa9/t0874dJ3OzNWCbfH6Yvsp9WpVV22CreoU6q9Oof4KqOXBpSsAQLEIN6hSGgX6aPaoSy803Xb8rF5fvl+749P1/f5Ufb8/1dnO6uWm+yJCddcNDdUo0EdWL14BAQC4hHCDKqtb0wB9Ne5m7U3M0OajZ3QoJVPbjp/ViTPZsufka87G45qz8bgkyd/HXX3C6mlkZGPdEOrPqA4A1GCEG1R57RrY1K6Bzbmck1egzcfO6F8bj2tfol1nsi4qPTtPS3cmaOnOBDX091bnxrVVx9dDPh6uuqlZoLo1DZCnG6+AAICagHCDasfL3VV9wuqpT9ill59m5ebrQLJd87fGKWpPshLSLygh/YKz/Qdrjsrb3VV9WtfVuD4tigQlAID5EG5Q7dXydFOXxgHq0jhAr99ZoC3Hz+hgcqbsF/J0OjNX6w6dVmpmrpbHJmt5bLKsXm4KqOWhBv7eeqZfS93YLNDoUwAAlCPCDUzF26PoqI4kORwO7U20a9b6Y/pmd6LsOfmy5+TrxJlsbTl2Ro/2aKrf39Jcdf243RwAzMDicDgcRhdRmex2u2w2mzIyMmS1Wo0uB5Us47+jOeeyL2rhtnh9ueOUJMnTzUW/6xqqx29pppDaPgZXCUCS7Dl5Cn95lSTp4GuDmDdXw5Xm9zcjN6hRbN7usnlfum28a5MADelQX+//eES749P16eaT+s/WOA1sF6T+bYN0W4cG8nDj9WsAUN3wNzdqtH5tgrTsye767LEbdXOLQBUUOrQ8Nll/+Hy37v9oi1Izc4wuEQBQSozcoMazWCzq3qKOureooz0JGVqxJ0nzNp/U9pPn1P/v6zW2V3ON7t5E3h4MiQNAdcDIDfAr7Rva9MeBrfXVuJvVJtiqjAt5ejPqgG55e40+3nBM9pw8o0sEAFwD4QYoRrO6vvr26R76+/COCqntrdOZuXrtu/26+Y0f9fGGYzqbddHoEgEAV0C4Aa7A1cWiuzuH6Mfnemvq3R3Usp6vMnPy9dp3+9X51dW6f/YWJf7qYYEAgKqBcANcg4ebi+7v1khRz96iN+/poBb1fCVJm4+d0eBpG/TSV3u08XCa8goKDa4UACAxoRgoMVcXi0Z0baQRXRvp5JksPfXZTsUmZOjTzSf16eaTqu3jrjG9mmtUZGP5ePBHCwCMwsgNUAaNA2tpyZPd9dGoCI2ICFUdXw+dy87TGysO6Ja31mjOxuPKySswukwAqJH45yVQRu6uLurf9tID//ILCvXVrkRN++Gw4s5m69Vv9+mj9cc0rm8LjYgI5WGAAFCJ+BsXKAduri66p0uIfniul6be3UENbF5KtufoL8v2aNgHm5Ri52GAAFBZCDdAOXJ3vTT5eM0fe+uVO9opoJaH9ifZddcHmxS1J0k17FVuAGAIwg1QATzdXPVQ9yb6atzNalanlhIzcjT2Pzt054c/6aejaUaXBwCmZmi4mTFjhsLDw2W1WmW1WhUZGakVK1ZcdZ9169apS5cu8vLyUrNmzTRz5sxKqhYovdAAH3311M0a37eFfDxctTs+XQ98tFUj52zVkdTzRpcHAKZkaLgJCQnRG2+8oZiYGMXExKhv374aNmyY9u7dW2z748ePa8iQIerZs6d27typyZMna/z48fryyy8ruXKg5Py83DVhQJjW/bGPRkU2lpuLRRsOp2nI+xs0a91RFRRyqQoAypPFUcUmAQQEBOjtt9/Wo48+etm2559/Xl9//bX279/vXDd27Fjt3r1bmzdvLtHx7Xa7bDabMjIyZLVay61uoKROnsnSi1/t1bpDpyVJnUL99c59HZ0PBwRwiT0nT+Evr5IkHXxtkDzdeHltTVaa399VZs5NQUGBFi5cqKysLEVGRhbbZvPmzRowYECRdQMHDlRMTIzy8nihIaqHxoG1NPfhrnrr3nD5ebppV3y6hry/Qa99u08HkzONLg8Aqj3Dw01sbKx8fX3l6empsWPHaunSpWrbtm2xbZOTkxUUFFRkXVBQkPLz85WWVvwkzdzcXNnt9iIfwGgWi0XDI0K1asIt6tWqri7mF+rjjcc18L31GvPvGB09zXwcACgrw8NNWFiYdu3apS1btuiJJ57QQw89pH379l2xvcViKbL8y1W1367/xdSpU2Wz2Zyf0NDQ8iseuE7BNm/Nfbir5jwUoYHtgmSxSCv3pmjQe+v1VtQBZV/MN7pEAKh2DA83Hh4eatGihSIiIjR16lR17NhR06ZNK7Zt/fr1lZycXGRdamqq3NzcFBgYWOw+kyZNUkZGhvMTHx9f7ucAXA+LxaJ+bYI0a2SEVj17i/qE1VVegUMfrj2q/n9frwXb4pSbz6scAKCkDA83v+VwOJSbm1vstsjISK1evbrIulWrVikiIkLu7u7F7uPp6em81fyXD1BVtQzy079Gd9WskV3U0N9bCekXNGlJrHq+uUYfbzimfN48DgDXZGi4mTx5sjZs2KATJ04oNjZWU6ZM0dq1a/Xggw9KujTqMmrUKGf7sWPH6uTJk5owYYL279+vf/3rX5ozZ44mTpxo1CkA5c5isWhgu/paPeEW/eX2tgq2eSk1M1evfbdfD8+NVnr2RaNLBIAqzdBwk5KSopEjRyosLEz9+vXT1q1bFRUVpf79+0uSkpKSFBcX52zftGlTLV++XGvXrlWnTp306quv6v3339c999xj1CkAFcbHw02P9miqdX/so7/d1UHe7q7acDhNvd9Zq3mbT6iQ5+MAQLGq3HNuKhrPuUF1tTcxQ3/4fJcOpVy6k6pnyzr6821tFVbfz+DKgIrBc27wa9XyOTcArq5dA5uWj++pl4e2lZe7izYcTtPA99brkbnROpDMIw4A4BeEG6AacXN10eibm+q78T01uH19uVikHw+kavC0Dfrj4t06dS7b6BIBwHCEG6Aaal7XVzP+r4t+eK63hnSoL4dDWrz9lHq9vVYTPt+lFHuO0SUCgGEIN0A11rROLX34YBctebK7bm4RqIJCh5bsTFC/d9fpy+2njC4PAAxBuAFMoHOj2pr/2E36atzN6hjqr/O5+Xpu8W796YvdunCRBwACqFkIN4CJdAz115InumtC/1ZysUiLYk5p2AcbFXsqw+jSAKDSEG4Ak3F1sWh8v5b6z2M3qo6vpw6lnNewDzZqwue7tP3kWaPLA4AKR7gBTKp78zpa8UxPDe3YQIUOacnOBN0zY7OenL9diekXjC4PACoM4QYwsbp+nvrn/TdoyZPddW+XELlYpOWxyer37jrNXn+UpxwDMCXCDVADdG5UW+/c11Hfje+prk1q60Jegf62/IDG/Ge77Dl5RpcHAOWKcAPUIG2CrVo0JlJ/u6uDPNxctHpfiu6cvkn7k3jCMQDzINwANYzFYtEDNzbS4jGRamDz0rG0LA15f4OeXbiTuTgATIFwA9RQHUP99c3TPTSo3aUnHC/blahb/75O87eeVA17ny4AkyHcADVYoK+nZo7som+f7qGIxrWVfbFAU5bu0XOLdys1k1c4AKieCDcA1L6hTYvHRuqFwa3lYpGW7EjQLW+t0dQV+3Uu66LR5QFAqRBuAEi6NBdnbK/mWvj7SN3QyF85eYWate6Y+r67Vl/vTjS6PAAoMcINgCK6NQ3Qkie6a85DEQoL8tO57DyNX7BTk5fG6mJ+odHlAcA1EW4AXMZisahfmyB983QPje/XUhaL9NnWON3/0Ral2pmLA6BqI9wAuCIPNxdN6N9K/xrdVX5ebtp+8pwGT9ugf/5wWJk8/A9AFUW4AXBNfcLq6euneqhlPV+dybqod1cf0m3vb9TOuHNGlwYAlyHcACiRpnVq6bvxPfXeiE5q6O+tuLPZum/mZn2w5ogKeEcVgCqEcAOgxDzcXHTnDQ21/Jmeuj08WPmFDr298qD+7+OtSs5gLg6AqoFwA6DUbN7u+uf9N+jte8Pl4+GqzcfOaOB767VsZwJvGgdgOMINgDKxWCy6LyJU3z7dQ+EhNmVcyNOzn+/SrX9fp6U7TxFyABiGcAPgujSr66svn+iu5/q3kp+Xm46lZekPn+/WnR9u0tZjZ4wuD0ANRLgBcN3cXV30dL+W2jypn/44MEy+nm76+VSGRszeojH/jtGJtCyjSwRQgxBuAJQbX083jevTQmsm9tYDNzaSi0VauTdF/f+xTq9+u0/ZF/ONLhFADUC4AVDu6vp56m93dVDUs7eod1hd5RU4NGfjcd0xfZOiT5yVw8F8HAAVh3ADoMK0CvLT3Ie7ae7DXVXPz1NHUs/rvpmbdd/MzTp1Ltvo8lDFkYFRVoQbABWud1g9LX+mp0ZEhMrDzUUxJ8/pjumb9O8tJ3U+l0tVKN6vX9Tq7sKvK5QcPy0AKkUdX0+9eW+41kzsrfYNrTqbdVF/WbZHPd78UR9vOKbc/AKjS0QV80vw9fV0k4uLxeBqUJ0QbgBUqob+3vpibHe9NLStmtWppfTsPL323X71fWedVsQmGV0eqpDzOf8LN0BpEG4AVDovd1c9fHNTrfrDLXrzng6qb/VSQvoFPTF/h8Yv2KkUO69ygJSZe+nN875ehBuUDuEGgGHcXF00omsjrZnYW0/1aSEXi/T17kT1fnut5m46zl1VNRwjNygrwg0Aw3l7uGriwDAtffJmdW7krwt5BXr5m30a/Um09ifZjS4PBvllzo0fIzcoJcINgCqjY6i/vnyiu165o508XF207tBpDZ62QX9bvr/InTOoGX49oRgoDcINgCrFYrHooe5NtOLZnrotPFiSNHv9MQ18b72W7Dil/AJCTk2RyWUplBHhBkCV1Lyurz54oLNmj+yiwFoeOp6WpQmLduvWv6/TN7sTmY9TAzhHbrgshVIi3ACo0ga0q6/1f+qj5we1VkAtD504k62nF+zUvTM3a3d8utHloQL9MqHYj5EblJKh4Wbq1Knq2rWr/Pz8VK9ePd155506ePDgNfebP3++OnbsKB8fHwUHB+vhhx/WmTNnKqFiAEao5emmJ3o314Y/9dGE/q3k7e6q7SfPadgHmzTm3zE6mJxpdImoAIzcoKwMDTfr1q3TuHHjtGXLFq1evVr5+fkaMGCAsrKyrrjPxo0bNWrUKD366KPau3evFi9erOjoaD322GOVWDkAI9TydNP4fi21ZmJv3X1DQ1n++9bx2/+5QR9vOKaCQi5Vmcn/5ty4G1wJqhtD43BUVFSR5U8++UT16tXT9u3bdcsttxS7z5YtW9SkSRONHz9ektS0aVONGTNGb731VoXXC6BqqG/z0t9HdNLY3s31VtQBfb8/Va99t19f7UrUlNva6MamAbJYeFx/dXeeh/ihjKrUnJuMjAxJUkBAwBXbdO/eXadOndLy5cvlcDiUkpKiL774Qrfddlux7XNzc2W324t8AJhDqyA/fTQqQn+7q4P8PN0Um5Ch383eontm/KTv96Uw6biacz7nhjk3KKUqE24cDocmTJigHj16qH379lds1717d82fP18jRoyQh4eH6tevL39/f/3zn/8stv3UqVNls9mcn9DQ0Io6BQAGsFgseuDGRvpxYm/9302N5OHmoh1x6XpsXowenhuttPO5RpeIMnI+oZiRG5RSlQk3Tz31lH7++WctWLDgqu327dun8ePH68UXX9T27dsVFRWl48ePa+zYscW2nzRpkjIyMpyf+Pj4iigfgMHq+nnqtTs7aOOf+mjMLc3k4eaitQdPq9+76/TR+mM8BLAaOp976U3xPOcGpWVxVIFx26efflrLli3T+vXr1bRp06u2HTlypHJycrR48WLnuo0bN6pnz55KTExUcHDwVfe32+2y2WzKyMiQ1Wotl/oBVD0Hku16duEuHfjvnVRtgq16575wtWtgM7gylFTrv6xQTl6hNvypj0IDfIwuBwYrze9vQ0duHA6HnnrqKS1ZskQ//vjjNYONJGVnZ8vFpWjZrq6uzuMBgCS1rm/Vd+N76q17wlXbx137k+waNn2T/r76EKM41UBeQaFy8i79f+LdUigtQ8PNuHHj9J///EefffaZ/Pz8lJycrOTkZF24cMHZZtKkSRo1apRzeejQoVqyZIlmzJihY8eOadOmTRo/fry6deumBg0aGHEaAKooVxeLhncN1ao/9NKgdvWVX+jQ+z8c1h3TN2r1vhTl8SqHKivrv5OJpUuPAABKw9CfmBkzZkiSevfuXWT9J598otGjR0uSkpKSFBcX59w2evRoZWZmavr06Xruuefk7++vvn376s0336yssgFUM3X9PDXj/zrru9gkvfjVXh1IztTj82IUWMtDd97QUPd0DlHbBlymrkp+ecaNt7ur3F2rzPRQVBNVYs5NZWLODVCzpZ3P1ax1R7V0Z2KRO6lubhGoN+8JV0ht5nZUBfuT7Bo8bYPq+nkqesqtRpeDKqDazLkBgMpWx9dTU25rq82T+mrOQxEa0qG+PFxdtOnIGQ38x3pN//Gw8/kqMA7PuMH14KcGQI3k7uqifm2C1K9NkE6kZWni4t2KOXlO76w6pOlrjmhA2/q6q3ND9WxRR25cFql0POMG14OfGgA1XpM6tbRoTKS++TlR0344rGOns/T17kR9vTtRdXw9NaJriH7fs7lsPrzjqLJk/vLSTEZuUAb81ACAJBcXi4Z1aqg7OjbQ7lMZWrYzQV/vvjQv54M1RzXvp5O6vWMD/d9NjXhWTiVwjtwQblAG/NQAwK9YLBZ1CvVXp1B/TbmtjX7Yn6J/rD6sgymZWrAtTgu2xalf63oa17eFOjeqbXS5pmXP+e9LMwk3KAN+agDgCtxdXTSofbAGtK2vLcfOaEF0vL77OVE/HEjVDwdS1SnUXyO6hmpw+/ry9/EwulxTOZGWJUlq4O9tcCWojgg3AHANLi4WdW9RR91b1NGE/q00Y+0RLd2ZoF3x6doVn66/LNujHi3raEiHYA1oG0TQKQf7f/XaDKC0eM4NAJTB6cxcfbnjlL7alaj9SXbnejcXiyKbB2pQ+/rq1zpI9W1eBlZZPRUUOtTupSjl5BXqh+d6qXldX6NLQhVQmt/fhBsAuE5HT5/Xt7uTtGJPkvNFnb8IsnqqX5sg3d4hWN2aBnBbeQkcO31efd9dJy93F+19ZZBcXSxGl4QqoDS/v7ksBQDXqXldXz1za0s9c2tLHU/L0oo9SVq5J1mxCRlKsefqs61x+mxrnOr4emhgu/q6LyJUnUL9jS67yvolIIYF+RFsUCaEGwAoR03r1NKTvVvoyd4tlH0xXzEnzml5bJKi9iYr7fxFzd8ap/lb4xTRuLZeGNxaEU0CjC65yvnlMl/r+oyuo2wINwBQQXw83HRLq7q6pVVdvXpne/109IyW7UzQdz8nKebkOd07c7MGt6+vcX1aqG2wVS6MUkiS9if9MpnYz+BKUF0RbgCgEri7uqhXq7rq1aquXhjcWv9YfUiLYuK1Yk+yVuxJVkAtD43t1UwPdW8iTzdXo8s1jMPh0J6EDElSa+6UQhkxsw0AKlmQ1Utv3BOu5c/01IC2QfLxcNXZrIv62/IDuvXv6/TF9lNKzcwxukxD7EuyK9meI293V+YlocwYuQEAg7Sub9XsURHKLyjUkp0JemflQcWfvaCJi3dLkro1DdDQjg3UvoFV4SH+NWJy7ff7UiVJPVvWkZd7zR3BwvUh3ACAwdxcXTQ8IlS3hwfr4w3HtTw2SQdTMrXt+FltO35WklTPz1O3hzfQHZ0aqGOITRaLOYPO6v3JkqRb2wYZXAmqM55zAwBVUFLGBS2OOaXtJ89pZ9w52f/7IklJahTgo991C9WDNzaWzdscbyqPO5OtmeuP6rOtcbJYpOgpt6qOr6fRZaEK4SF+V0G4AVDdXMwv1PpDp/XNz4lavS9F2RcLJEmebi66tU2Qbm5RR12b1Fbzur7V8o6ri/mFGvCPdTpxJluSFNksUAt+f5PBVaGq4SF+AGAiHm4uurVtkG5tG6Tsi/laHpusjzcc04HkTH0Xm6TvYpMkSTZvd0U0rq1eYXU1qF191bNWj1c//HvLSZ04k606vp6aNLi1+rauZ3RJqOYYuQGAasjhcGhvol2r9iYr+sQ57YpP14W8Aud2NxeLbg8P1mM9m6l9Q5uBlV7O4XBo7aHT+nZ3kqJPnNWpc9kqdEhT7+6g+7s1Mro8VFFclroKwg0AM8orKNS+RLs2HzujFXuStTs+3bmtS+PaGty+vga2q6/QAJ9Kr+2XILZsZ4L2JGYoPTvvsndwdWlcW4vGRNaIO8JQNoSbqyDcAKgJfj6Vro83HNd3sUkqKPzfX/Ntg626pVVdBdu81K6BVe0b2sr9lmuHw6FjaVk6nHJeO+PP6cf9qTqcer5IGy93F/2uayP1bV1PrYL8FGT1NO0dYCgfhJur+KVzkk6fIdwAML2UjFx9vz9Fq/elKPrEWf32L3w3F6lNsE03NgtQaG0febpbVM/PS/Wt3gqyesrbw1U5eQVKy7yo0+dzlHb+olwkeXm4ytPNVRcu5qvQ4dCZ83lae+jSM2qS0nO097/vh/qFu6tFfVvXU69WdeXh5qKujQNU18rdUCg5u92u4LqBhJviZGRkyN/fXw2fmCsXz8ofngUAAKVXmJuthBmjlZ6eLpvt6vPIatzdUmfOnJEkJcwYbWwhAACg1DIzMwk3vxUQECBJiouLu2bnXI+uXbsqOjq6Qve9VrurbS9uW2nX2e12hYaGKj4+vkIv8Zm1L3+9TF9eeRt9SV+Wx770ZfntV9a+LM364vpy27ZtyszMVIMGDa5ZY40LNy4ul94VarPZKvQHzNXVtczHL+m+12p3te3FbSvrOqvVSl+Wod+Ka0Nf0pelaUdf0pclqbW89ytrX5ZmfXF9abPZSjwowVvBK8i4ceMqfN9rtbva9uK2Xc+6imTWvqzsfrze76Qvr15DRexLX5bfvvRl+e1X1r4szfrr7csaN6GYW8HLD31ZfujL8kNflh/6svzQl5Wrxo3ceHp66qWXXpKnJ7cgXi/6svzQl+WHviw/9GX5oS8rV40buQEAAOZW40ZuAACAuRFuAACAqRBuAACAqRBuAACAqRBuAACAqRBursHNzU2dOnVSp06d9NhjjxldTrWXnZ2txo0ba+LEiUaXUm1lZmaqa9eu6tSpkzp06KCPPvrI6JKqrfj4ePXu3Vtt27ZVeHi4Fi9ebHRJ1dZdd92l2rVr69577zW6lGrn22+/VVhYmFq2bKmPP/7Y6HJMgVvBr6FOnTpKS0szugzTmDJlig4fPqxGjRrpnXfeMbqcaqmgoEC5ubny8fFRdna22rdvr+joaAUGBhpdWrWTlJSklJQUderUSampqercubMOHjyoWrVqGV1atbNmzRqdP39en376qb744gujy6k28vPz1bZtW61Zs0ZWq1WdO3fW1q1bne9BRNkwcoNKc/jwYR04cEBDhgwxupRqzdXVVT4+PpKknJwcFRQUiH+jlE1wcLA6deokSapXr54CAgJ09uxZY4uqpvr06SM/Pz+jy6h2tm3bpnbt2qlhw4by8/PTkCFDtHLlSqPLqvaqdbhZv369hg4dqgYNGshisWjZsmWXtfnwww/VtGlTeXl5qUuXLtqwYUOpvsNut6tLly7q0aOH1q1bV06VVz2V0ZcTJ07U1KlTy6niqqsy+jI9PV0dO3ZUSEiI/vSnP6lOnTrlVH3VUhl9+YuYmBgVFhYqNDT0OquueiqzH2ua6+3bxMRENWzY0LkcEhKihISEyijd1Kp1uMnKylLHjh01ffr0Yrd//vnnevbZZzVlyhTt3LlTPXv21ODBgxUXF+ds06VLF7Vv3/6yT2JioiTpxIkT2r59u2bOnKlRo0bJbrdXyrlVtoruy6+++kqtWrVSq1atKuuUDFMZP5f+/v7avXu3jh8/rs8++0wpKSmVcm6VrTL6UpLOnDmjUaNGafbs2RV+TkaorH6sia63b4sbdbVYLBVac43gMAlJjqVLlxZZ161bN8fYsWOLrGvdurXjhRdeKNN3DBo0yBEdHV3WEquNiujLF154wRESEuJo3LixIzAw0GG1Wh2vvPJKeZVcZVXGz+XYsWMdixYtKmuJ1UZF9WVOTo6jZ8+ejnnz5pVHmVVeRf5MrlmzxnHPPfdcb4nVVln6dtOmTY4777zTuW38+PGO+fPnV3itZletR26u5uLFi9q+fbsGDBhQZP2AAQP0008/legY586dU25uriTp1KlT2rdvn5o1a1butVZ15dGXU6dOVXx8vE6cOKF33nlHjz/+uF588cWKKLdKK4++TElJcY4g2u12rV+/XmFhYeVea1VXHn3pcDg0evRo9e3bVyNHjqyIMqu88uhHFK8kfdutWzft2bNHCQkJyszM1PLlyzVw4EAjyjUVN6MLqChpaWkqKChQUFBQkfVBQUFKTk4u0TH279+vMWPGyMXFRRaLRdOmTauRM9jLoy9xSXn05alTp/Too4/K4XDI4XDoqaeeUnh4eEWUW6WVR19u2rRJn3/+ucLDw51zJf7973+rQ4cO5V1ulVVef74HDhyoHTt2KCsrSyEhIVq6dKm6du1a3uVWKyXpWzc3N7377rvq06ePCgsL9ac//Yk7H8uBacPNL3577dLhcJT4emb37t0VGxtbEWVVS9fTl782evTocqqo+rqevuzSpYt27dpVAVVVT9fTlz169FBhYWFFlFXtXO+fb+7wubJr9e0dd9yhO+64o7LLMjXTXpaqU6eOXF1dL/uXR2pq6mUpGldHX5Yf+rL80Jflg36sOPStcUwbbjw8PNSlSxetXr26yPrVq1ere/fuBlVVPdGX5Ye+LD/0ZfmgHysOfWucan1Z6vz58zpy5Ihz+fjx49q1a5cCAgLUqFEjTZgwQSNHjlRERIQiIyM1e/ZsxcXFaezYsQZWXTXRl+WHviw/9GX5oB8rDn1bRRl2n1Y5WLNmjUPSZZ+HHnrI2eaDDz5wNG7c2OHh4eHo3LmzY926dcYVXIXRl+WHviw/9GX5oB8rDn1bNfFuKQAAYCqmnXMDAABqJsINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINAAAwFcINgGqpSZMmeu+994wuA0AVxBOKAVzR6NGjlZ6ermXLlhldymVOnz6tWrVqycfHx+hSilWV+w4wO0ZuAFQpeXl5JWpXt25dQ4JNSesDYBzCDYAy27dvn4YMGSJfX18FBQVp5MiRSktLc26PiopSjx495O/vr8DAQN1+++06evSoc/uJEydksVi0aNEi9e7dW15eXvrPf/6j0aNH684779Q777yj4OBgBQYGaty4cUWCxW8vS1ksFn388ce666675OPjo5YtW+rrr78uUu/XX3+tli1bytvbW3369NGnn34qi8Wi9PT0K56jxWLRzJkzNWzYMNWqVUuvvfaaCgoK9Oijj6pp06by9vZWWFiYpk2b5tzn5Zdf1qeffqqvvvpKFotFFotFa9eulSQlJCRoxIgRql27tgIDAzVs2DCdOHGibP8DABSLcAOgTJKSktSrVy916tRJMTExioqKUkpKioYPH+5sk5WVpQkTJig6Olo//PCDXFxcdNddd6mwsLDIsZ5//nmNHz9e+/fv18CBAyVJa9as0dGjR7VmzRp9+umnmjt3rubOnXvVml555RUNHz5cP//8s4YMGaIHH3xQZ8+elXQpSN1777268847tWvXLo0ZM0ZTpkwp0bm+9NJLGjZsmGJjY/XII4+osLBQISEhWrRokfbt26cXX3xRkydP1qJFiyRJEydO1PDhwzVo0CAlJSUpKSlJ3bt3V3Z2tvr06SNfX1+tX79eGzdulK+vrwYNGqSLFy+WtOsBXIuxLyUHUJU99NBDjmHDhhW77S9/+YtjwIABRdbFx8c7JDkOHjxY7D6pqakOSY7Y2FiHw+FwHD9+3CHJ8d577132vY0bN3bk5+c71913332OESNGOJcbN27s+Mc//uFcluT485//7Fw+f/68w2KxOFasWOFwOByO559/3tG+ffsi3zNlyhSHJMe5c+eK74D/HvfZZ5+94vZfPPnkk4577rmnyDn8tu/mzJnjCAsLcxQWFjrX5ebmOry9vR0rV6685ncAKBlGbgCUyfbt27VmzRr5+vo6P61bt5Yk56Wno0eP6oEHHlCzZs1ktVrVtGlTSVJcXFyRY0VERFx2/Hbt2snV1dW5HBwcrNTU1KvWFB4e7vzvWrVqyc/Pz7nPwYMH1bVr1yLtu3XrVqJzLa6+mTNnKiIiQnXr1pWvr68++uijy87rt7Zv364jR47Iz8/P2WcBAQHKyckpcrkOwPVxM7oAANVTYWGhhg4dqjfffPOybcHBwZKkoUOHKjQ0VB999JEaNGigwsJCtW/f/rJLMLVq1brsGO7u7kWWLRbLZZezSrOPw+GQxWIpst1RwptFf1vfokWL9Ic//EHvvvuuIiMj5efnp7fffltbt2696nEKCwvVpUsXzZ8//7JtdevWLVEtAK6NcAOgTDp37qwvv/xSTZo0kZvb5X+VnDlzRvv379esWbPUs2dPSdLGjRsru0yn1q1ba/ny5UXWxcTElOlYGzZsUPfu3fXkk0861/125MXDw0MFBQVF1nXu3Fmff/656tWrJ6vVWqbvBnBtXJYCcFUZGRnatWtXkU9cXJzGjRuns2fP6v7779e2bdt07NgxrVq1So888ogKCgqcdwPNnj1bR44c0Y8//qgJEyYYdh5jxozRgQMH9Pzzz+vQoUNatGiRc4Lyb0d0rqVFixaKiYnRypUrdejQIf3lL39RdHR0kTZNmjTRzz//rIMHDyotLU15eXl68MEHVadOHQ0bNkwbNmzQ8ePHtW7dOj3zzDM6depUeZ0qUOMRbgBc1dq1a3XDDTcU+bz44otq0KCBNm3apIKCAg0cOFDt27fXM888I5vNJhcXF7m4uGjhwoXavn272rdvrz/84Q96++23DTuPpk2b6osvvtCSJUsUHh6uGTNmOO+W8vT0LNWxxo4dq7vvvlsjRozQjTfeqDNnzhQZxZGkxx9/XGFhYc55OZs2bZKPj4/Wr1+vRo0a6e6771abNm30yCOP6MKFC4zkAOWIJxQDqLFef/11zZw5U/Hx8UaXAqAcMecGQI3x4YcfqmvXrgoMDNSmTZv09ttv66mnnjK6LADljHADoMY4fPiwXnvtNZ09e1aNGjXSc889p0mTJhldFoByxmUpAABgKkwoBgAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApkK4AQAApvL/3uYKxGcSdpwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)\n",
    "plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 1.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "985d5068",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-2)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d7e13f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cae2a32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "352/352 [==============================] - 4s 8ms/step - loss: 2.0702 - accuracy: 0.2755 - val_loss: 1.7708 - val_accuracy: 0.3596\n",
      "Epoch 2/15\n",
      "352/352 [==============================] - 3s 7ms/step - loss: 1.7748 - accuracy: 0.3705 - val_loss: 1.6709 - val_accuracy: 0.4064\n",
      "Epoch 3/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.6346 - accuracy: 0.4191 - val_loss: 1.6324 - val_accuracy: 0.4228\n",
      "Epoch 4/15\n",
      "352/352 [==============================] - 3s 7ms/step - loss: 1.5480 - accuracy: 0.4519 - val_loss: 1.6184 - val_accuracy: 0.4260\n",
      "Epoch 5/15\n",
      "352/352 [==============================] - 3s 7ms/step - loss: 1.4943 - accuracy: 0.4695 - val_loss: 1.6650 - val_accuracy: 0.4358\n",
      "Epoch 6/15\n",
      "352/352 [==============================] - 3s 7ms/step - loss: 1.4550 - accuracy: 0.4820 - val_loss: 1.5920 - val_accuracy: 0.4498\n",
      "Epoch 7/15\n",
      "352/352 [==============================] - 3s 7ms/step - loss: 1.4124 - accuracy: 0.4983 - val_loss: 1.6103 - val_accuracy: 0.4542\n",
      "Epoch 8/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.3466 - accuracy: 0.5221 - val_loss: 1.4885 - val_accuracy: 0.4906\n",
      "Epoch 9/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.2711 - accuracy: 0.5468 - val_loss: 1.5547 - val_accuracy: 0.4752\n",
      "Epoch 10/15\n",
      "352/352 [==============================] - 3s 7ms/step - loss: 1.1992 - accuracy: 0.5710 - val_loss: 1.4789 - val_accuracy: 0.5094\n",
      "Epoch 11/15\n",
      "352/352 [==============================] - 3s 7ms/step - loss: 1.1308 - accuracy: 0.5987 - val_loss: 1.5010 - val_accuracy: 0.5026\n",
      "Epoch 12/15\n",
      "352/352 [==============================] - 3s 7ms/step - loss: 1.0618 - accuracy: 0.6231 - val_loss: 1.5154 - val_accuracy: 0.5114\n",
      "Epoch 13/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 0.9928 - accuracy: 0.6456 - val_loss: 1.5237 - val_accuracy: 0.5240\n",
      "Epoch 14/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 0.9274 - accuracy: 0.6706 - val_loss: 1.5456 - val_accuracy: 0.5310\n",
      "Epoch 15/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 0.8859 - accuracy: 0.6851 - val_loss: 1.5742 - val_accuracy: 0.5250\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "onecycle = OneCycleScheduler(math.ceil(len(X_train_scaled) / batch_size) * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146db8ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
